{"ast":null,"code":"var _jsxFileName = \"E:\\\\test project\\\\frontend\\\\src\\\\components\\\\VoiceInput.tsx\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect, useRef } from 'react';\nimport './VoiceInput.css';\nimport { jsxDEV as _jsxDEV, Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nconst VoiceInput = ({\n  onSpeechResult,\n  disabled = false\n}) => {\n  _s();\n  const [isListening, setIsListening] = useState(false);\n  const [speechRecognition, setSpeechRecognition] = useState(null);\n  const [animationLevel, setAnimationLevel] = useState(0);\n  const [voiceAmplitude, setVoiceAmplitude] = useState([0, 0, 0, 0, 0]);\n  const [errorMessage, setErrorMessage] = useState(null);\n  const [recognitionState, setRecognitionState] = useState('idle');\n  const [interimTranscript, setInterimTranscript] = useState('');\n  const [isSpeaking, setIsSpeaking] = useState(false);\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n  const mediaStreamRef = useRef(null);\n  const startTimeRef = useRef(0);\n  const speechSynthesisRef = useRef(null);\n  const previousStateRef = useRef('idle');\n\n  // Speak the current state using speech synthesis\n  const speakState = (state, errorMsg) => {\n    // Don't speak if already speaking\n    if (isSpeaking) {\n      if (speechSynthesisRef.current) {\n        window.speechSynthesis.cancel();\n      }\n    }\n\n    // Don't repeat the same state\n    if (state === previousStateRef.current && state !== 'error') {\n      return;\n    }\n    previousStateRef.current = state;\n\n    // Create message based on state\n    let message = '';\n    switch (state) {\n      case 'listening':\n        message = \"I'm listening. Please speak now.\";\n        break;\n      case 'processing':\n        message = \"Processing your speech.\";\n        break;\n      case 'error':\n        message = errorMsg || \"An error occurred with speech recognition.\";\n        break;\n      case 'idle':\n        message = \"Voice input ready.\";\n        break;\n      default:\n        return;\n      // Don't speak for unknown states\n    }\n\n    // Use speech synthesis to speak the message\n    if ('speechSynthesis' in window) {\n      const utterance = new SpeechSynthesisUtterance(message);\n      utterance.volume = 0.8;\n      utterance.rate = 1.1;\n      utterance.pitch = 1.0;\n\n      // Set voice (try to use a female voice if available)\n      const voices = window.speechSynthesis.getVoices();\n      const femaleVoice = voices.find(voice => voice.name.includes('female') || voice.name.includes('Samantha') || voice.name.includes('Google UK English Female'));\n      if (femaleVoice) {\n        utterance.voice = femaleVoice;\n      }\n\n      // Handle events\n      utterance.onstart = () => {\n        setIsSpeaking(true);\n      };\n      utterance.onend = () => {\n        setIsSpeaking(false);\n        speechSynthesisRef.current = null;\n      };\n      utterance.onerror = event => {\n        console.error('Speech synthesis error:', event);\n        setIsSpeaking(false);\n        speechSynthesisRef.current = null;\n      };\n\n      // Store reference and speak\n      speechSynthesisRef.current = utterance;\n      window.speechSynthesis.speak(utterance);\n    }\n  };\n\n  // Load voices when available\n  useEffect(() => {\n    if ('speechSynthesis' in window) {\n      // Chrome needs this to load voices\n      window.speechSynthesis.onvoiceschanged = () => {\n        window.speechSynthesis.getVoices();\n      };\n    }\n  }, []);\n\n  // Audio processing for voice visualization\n  const setupAudioProcessing = async () => {\n    try {\n      // Create audio context\n      const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n      audioContextRef.current = audioContext;\n\n      // Get microphone stream\n      const stream = await navigator.mediaDevices.getUserMedia({\n        audio: true\n      });\n      mediaStreamRef.current = stream;\n\n      // Create analyser node\n      const analyser = audioContext.createAnalyser();\n      analyser.fftSize = 32; // Small FFT size for performance\n      analyserRef.current = analyser;\n\n      // Connect microphone to analyser\n      const source = audioContext.createMediaStreamSource(stream);\n      source.connect(analyser);\n\n      // Start visualization loop\n      visualizeAudio();\n    } catch (err) {\n      console.error('Error setting up audio visualization:', err);\n      setErrorMessage('Could not access microphone for visualization');\n    }\n  };\n\n  // Clean up audio processing\n  const cleanupAudioProcessing = () => {\n    if (mediaStreamRef.current) {\n      mediaStreamRef.current.getTracks().forEach(track => track.stop());\n      mediaStreamRef.current = null;\n    }\n    if (audioContextRef.current) {\n      audioContextRef.current.close().catch(err => {\n        console.error('Error closing audio context:', err);\n      });\n      audioContextRef.current = null;\n    }\n    analyserRef.current = null;\n    setVoiceAmplitude([0, 0, 0, 0, 0]);\n  };\n\n  // Visualize audio data\n  const visualizeAudio = () => {\n    if (!analyserRef.current || !isListening) return;\n    const bufferLength = analyserRef.current.frequencyBinCount;\n    const dataArray = new Uint8Array(bufferLength);\n    const updateAmplitude = () => {\n      if (!analyserRef.current || !isListening) return;\n\n      // Get frequency data\n      analyserRef.current.getByteFrequencyData(dataArray);\n\n      // Calculate average amplitude from different frequency ranges\n      const bass = dataArray.slice(0, 3).reduce((a, b) => a + b, 0) / 3;\n      const midLow = dataArray.slice(3, 6).reduce((a, b) => a + b, 0) / 3;\n      const mid = dataArray.slice(6, 9).reduce((a, b) => a + b, 0) / 3;\n      const midHigh = dataArray.slice(9, 12).reduce((a, b) => a + b, 0) / 3;\n      const high = dataArray.slice(12, 15).reduce((a, b) => a + b, 0) / 3;\n\n      // Normalize values (0-1)\n      const normalized = [bass / 255, midLow / 255, mid / 255, midHigh / 255, high / 255];\n      setVoiceAmplitude(normalized);\n\n      // Continue animation loop\n      requestAnimationFrame(updateAmplitude);\n    };\n    updateAmplitude();\n  };\n\n  // Animation effect\n  useEffect(() => {\n    let animationInterval = null;\n    if (isListening) {\n      // Set up audio processing for visualization\n      setupAudioProcessing();\n\n      // Fallback animation for wave effect\n      animationInterval = setInterval(() => {\n        setAnimationLevel(prev => (prev + 1) % 4); // Cycle through 0-3\n      }, 300);\n    } else {\n      // Clean up audio processing\n      cleanupAudioProcessing();\n      if (animationInterval) {\n        clearInterval(animationInterval);\n        setAnimationLevel(0);\n      }\n    }\n    return () => {\n      if (animationInterval) clearInterval(animationInterval);\n      cleanupAudioProcessing();\n    };\n  }, [isListening]);\n\n  // Initialize speech recognition\n  useEffect(() => {\n    if (typeof window !== 'undefined') {\n      // Check if browser supports speech recognition\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n      if (SpeechRecognition) {\n        const recognition = new SpeechRecognition();\n\n        // Configure recognition\n        recognition.continuous = true;\n        recognition.interimResults = true;\n        recognition.maxAlternatives = 1;\n        recognition.lang = 'en-US';\n\n        // Handle interim results (while speaking)\n        recognition.onresult = event => {\n          let finalTranscript = '';\n          let interimTranscript = '';\n\n          // Process results\n          for (let i = event.resultIndex; i < event.results.length; i++) {\n            const transcript = event.results[i][0].transcript;\n            if (event.results[i].isFinal) {\n              finalTranscript += transcript;\n              setRecognitionState('processing');\n              speakState('processing');\n            } else {\n              interimTranscript += transcript;\n            }\n          }\n\n          // Update interim transcript for display\n          if (interimTranscript) {\n            setInterimTranscript(interimTranscript);\n          }\n\n          // If we have a final result, send it\n          if (finalTranscript) {\n            // Calculate speech speed (words per minute)\n            const wordCount = finalTranscript.split(/\\s+/).length;\n            const speechDuration = (Date.now() - startTimeRef.current) / 1000 / 60; // in minutes\n            const wordsPerMinute = Math.round(wordCount / speechDuration);\n\n            // Send the result with metadata\n            onSpeechResult(finalTranscript);\n\n            // Log speech analytics\n            console.log(`Speech detected: ${finalTranscript}`);\n            console.log(`Speech duration: ${(speechDuration * 60).toFixed(2)} seconds`);\n            console.log(`Words per minute: ${wordsPerMinute}`);\n\n            // Reset state\n            setInterimTranscript('');\n            setRecognitionState('idle');\n            setIsListening(false);\n          }\n        };\n        recognition.onerror = event => {\n          console.error('Speech recognition error', event.error);\n          let errorMsg = 'Error with speech recognition';\n          let shouldRestart = false;\n\n          // Provide more specific error messages\n          switch (event.error) {\n            case 'no-speech':\n              errorMsg = 'No speech detected. Please try speaking again.';\n              shouldRestart = true; // Auto-restart on no-speech\n              break;\n            case 'aborted':\n              errorMsg = 'Speech recognition was aborted. Restarting...';\n              shouldRestart = true; // Auto-restart on aborted\n              break;\n            case 'audio-capture':\n              errorMsg = 'Could not capture audio. Please check your microphone.';\n              break;\n            case 'network':\n              errorMsg = 'Network error occurred. Please check your connection.';\n              break;\n            case 'not-allowed':\n              errorMsg = 'Microphone access denied. Please allow microphone access.';\n              break;\n            case 'service-not-allowed':\n              errorMsg = 'Speech recognition service not allowed.';\n              break;\n            case 'bad-grammar':\n              errorMsg = 'Grammar error in speech recognition.';\n              break;\n            case 'language-not-supported':\n              errorMsg = 'Language not supported for speech recognition.';\n              break;\n            default:\n              errorMsg = `Error: ${event.error}`;\n          }\n          setErrorMessage(errorMsg);\n\n          // Only change state if we're not going to restart\n          if (!shouldRestart) {\n            setRecognitionState('error');\n            speakState('error', errorMsg);\n            setIsListening(false);\n          } else {\n            // For no-speech or aborted, just show a temporary message\n            setTimeout(() => {\n              setErrorMessage(null);\n\n              // Try to restart recognition if we're still supposed to be listening\n              if (isListening) {\n                try {\n                  recognition.start();\n                  console.log('Speech recognition restarted after error');\n                } catch (e) {\n                  console.error('Failed to restart speech recognition', e);\n                  setRecognitionState('error');\n                  speakState('error', 'Failed to restart speech recognition');\n                  setIsListening(false);\n                }\n              }\n            }, 1500);\n          }\n        };\n        recognition.onstart = () => {\n          setRecognitionState('listening');\n          startTimeRef.current = Date.now();\n          console.log('Speech recognition started');\n          speakState('listening');\n        };\n        recognition.onend = () => {\n          console.log('Speech recognition ended');\n\n          // If we're still supposed to be listening, restart the recognition\n          if (isListening && recognitionState === 'listening') {\n            try {\n              // Add a small delay to prevent rapid restarts\n              setTimeout(() => {\n                if (isListening) {\n                  recognition.start();\n                  console.log('Speech recognition restarted');\n                }\n              }, 300);\n            } catch (e) {\n              console.error('Failed to restart speech recognition', e);\n              setRecognitionState('error');\n              speakState('error', 'Failed to restart speech recognition');\n              setIsListening(false);\n            }\n          } else if (recognitionState === 'listening') {\n            // Only update state if we're still in listening state\n            setRecognitionState('idle');\n            setIsListening(false);\n          }\n        };\n\n        // Handle audio start/end events\n        recognition.onaudiostart = () => {\n          console.log('Audio capturing started');\n        };\n        recognition.onaudioend = () => {\n          console.log('Audio capturing ended');\n        };\n\n        // Handle sound start/end events\n        recognition.onsoundstart = () => {\n          console.log('Sound detected');\n        };\n        recognition.onsoundend = () => {\n          console.log('Sound ended');\n        };\n\n        // Handle speech start/end events\n        recognition.onspeechstart = () => {\n          console.log('Speech started');\n        };\n        recognition.onspeechend = () => {\n          console.log('Speech ended');\n        };\n        setSpeechRecognition(recognition);\n      } else {\n        setErrorMessage('Speech recognition not supported in this browser');\n        setRecognitionState('error');\n        speakState('error', 'Speech recognition not supported in this browser');\n      }\n    }\n  }, [onSpeechResult]);\n  const toggleListening = () => {\n    if (disabled || !speechRecognition) return;\n\n    // Cancel any ongoing speech synthesis\n    if (speechSynthesisRef.current) {\n      window.speechSynthesis.cancel();\n      speechSynthesisRef.current = null;\n      setIsSpeaking(false);\n    }\n    if (isListening) {\n      // Stop listening\n      speechRecognition.stop();\n      setIsListening(false);\n      setRecognitionState('idle');\n      setInterimTranscript('');\n      speakState('idle');\n    } else {\n      // Start listening\n      setErrorMessage(null);\n      setRecognitionState('listening');\n      startTimeRef.current = Date.now();\n      try {\n        speechRecognition.start();\n        setIsListening(true);\n        // Note: We don't call speakState here because it will be called in the onstart event\n      } catch (error) {\n        console.error('Error starting speech recognition:', error);\n        const errorMsg = 'Failed to start speech recognition. Please try again.';\n        setErrorMessage(errorMsg);\n        setRecognitionState('error');\n        speakState('error', errorMsg);\n      }\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"voice-input-container\",\n    children: [/*#__PURE__*/_jsxDEV(\"button\", {\n      className: `voice-input-button ${recognitionState === 'listening' ? 'listening' : ''} ${recognitionState === 'processing' ? 'processing' : ''} ${recognitionState === 'error' ? 'error' : ''} ${isSpeaking ? 'speaking' : ''} ${disabled ? 'disabled' : ''}`,\n      onClick: toggleListening,\n      disabled: disabled || !speechRecognition || recognitionState === 'processing' || isSpeaking,\n      title: errorMessage || (isSpeaking ? 'System is speaking' : isListening ? 'Tap to stop' : 'Tap to speak'),\n      \"aria-label\": \"Voice input\",\n      children: [/*#__PURE__*/_jsxDEV(\"svg\", {\n        className: \"microphone-svg\",\n        width: \"24\",\n        height: \"24\",\n        viewBox: \"0 0 24 24\",\n        fill: \"none\",\n        xmlns: \"http://www.w3.org/2000/svg\",\n        children: [/*#__PURE__*/_jsxDEV(\"rect\", {\n          x: \"9\",\n          y: \"2\",\n          width: \"6\",\n          height: \"12\",\n          rx: \"3\",\n          fill: isListening ? \"#FFFFFF\" : recognitionState === 'error' ? \"#FF5555\" : \"#555555\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 473,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"path\", {\n          d: \"M5 10V11C5 14.866 8.13401 18 12 18V18C15.866 18 19 14.866 19 11V10\",\n          stroke: isListening ? \"#FFFFFF\" : recognitionState === 'error' ? \"#FF5555\" : \"#555555\",\n          strokeWidth: \"2\",\n          strokeLinecap: \"round\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 482,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"line\", {\n          x1: \"12\",\n          y1: \"18\",\n          x2: \"12\",\n          y2: \"22\",\n          stroke: isListening ? \"#FFFFFF\" : recognitionState === 'error' ? \"#FF5555\" : \"#555555\",\n          strokeWidth: \"2\",\n          strokeLinecap: \"round\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 489,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"line\", {\n          x1: \"8\",\n          y1: \"22\",\n          x2: \"16\",\n          y2: \"22\",\n          stroke: isListening ? \"#FFFFFF\" : recognitionState === 'error' ? \"#FF5555\" : \"#555555\",\n          strokeWidth: \"2\",\n          strokeLinecap: \"round\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 499,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 464,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: `status-indicator ${isSpeaking ? 'speaking' : recognitionState}`\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 511,\n        columnNumber: 9\n      }, this), isListening && /*#__PURE__*/_jsxDEV(_Fragment, {\n        children: [/*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"voice-amplitude\",\n          children: voiceAmplitude.map((level, index) => /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"amplitude-bar\",\n            style: {\n              height: `${Math.max(3, level * 30)}px`,\n              opacity: Math.max(0.4, level),\n              backgroundColor: `hsl(${210 + index * 15}, 80%, ${50 + level * 25}%)`,\n              transform: `scaleY(${1 + level * 0.2})`\n            }\n          }, index, false, {\n            fileName: _jsxFileName,\n            lineNumber: 518,\n            columnNumber: 17\n          }, this))\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 516,\n          columnNumber: 13\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"sound-waves\",\n          children: [/*#__PURE__*/_jsxDEV(\"div\", {\n            className: `wave wave-1 ${animationLevel >= 1 ? 'active' : ''}`\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 533,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: `wave wave-2 ${animationLevel >= 2 ? 'active' : ''}`\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 534,\n            columnNumber: 15\n          }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n            className: `wave wave-3 ${animationLevel >= 3 ? 'active' : ''}`\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 535,\n            columnNumber: 15\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 532,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 457,\n      columnNumber: 7\n    }, this), recognitionState === 'listening' && interimTranscript && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"interim-transcript\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"transcript-text\",\n        children: interimTranscript\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 544,\n        columnNumber: 11\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"listening-indicator\",\n        children: \"Listening...\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 545,\n        columnNumber: 11\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 543,\n      columnNumber: 9\n    }, this), recognitionState === 'processing' && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"processing-indicator\",\n      children: \"Processing...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 550,\n      columnNumber: 9\n    }, this), errorMessage && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"voice-input-error\",\n      children: errorMessage\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 553,\n      columnNumber: 24\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 456,\n    columnNumber: 5\n  }, this);\n};\n_s(VoiceInput, \"udoE9oojDoq1aexMokgVb0wbK1M=\");\n_c = VoiceInput;\nexport default VoiceInput;\nvar _c;\n$RefreshReg$(_c, \"VoiceInput\");","map":{"version":3,"names":["React","useState","useEffect","useRef","jsxDEV","_jsxDEV","Fragment","_Fragment","VoiceInput","onSpeechResult","disabled","_s","isListening","setIsListening","speechRecognition","setSpeechRecognition","animationLevel","setAnimationLevel","voiceAmplitude","setVoiceAmplitude","errorMessage","setErrorMessage","recognitionState","setRecognitionState","interimTranscript","setInterimTranscript","isSpeaking","setIsSpeaking","audioContextRef","analyserRef","mediaStreamRef","startTimeRef","speechSynthesisRef","previousStateRef","speakState","state","errorMsg","current","window","speechSynthesis","cancel","message","utterance","SpeechSynthesisUtterance","volume","rate","pitch","voices","getVoices","femaleVoice","find","voice","name","includes","onstart","onend","onerror","event","console","error","speak","onvoiceschanged","setupAudioProcessing","audioContext","AudioContext","webkitAudioContext","stream","navigator","mediaDevices","getUserMedia","audio","analyser","createAnalyser","fftSize","source","createMediaStreamSource","connect","visualizeAudio","err","cleanupAudioProcessing","getTracks","forEach","track","stop","close","catch","bufferLength","frequencyBinCount","dataArray","Uint8Array","updateAmplitude","getByteFrequencyData","bass","slice","reduce","a","b","midLow","mid","midHigh","high","normalized","requestAnimationFrame","animationInterval","setInterval","prev","clearInterval","SpeechRecognition","webkitSpeechRecognition","recognition","continuous","interimResults","maxAlternatives","lang","onresult","finalTranscript","i","resultIndex","results","length","transcript","isFinal","wordCount","split","speechDuration","Date","now","wordsPerMinute","Math","round","log","toFixed","shouldRestart","setTimeout","start","e","onaudiostart","onaudioend","onsoundstart","onsoundend","onspeechstart","onspeechend","toggleListening","className","children","onClick","title","width","height","viewBox","fill","xmlns","x","y","rx","fileName","_jsxFileName","lineNumber","columnNumber","d","stroke","strokeWidth","strokeLinecap","x1","y1","x2","y2","map","level","index","style","max","opacity","backgroundColor","transform","_c","$RefreshReg$"],"sources":["E:/test project/frontend/src/components/VoiceInput.tsx"],"sourcesContent":["import React, { useState, useEffect, useRef } from 'react';\nimport './VoiceInput.css';\n\ninterface VoiceInputProps {\n  onSpeechResult: (text: string) => void;\n  disabled?: boolean;\n}\n\nconst VoiceInput: React.FC<VoiceInputProps> = ({ onSpeechResult, disabled = false }) => {\n  const [isListening, setIsListening] = useState(false);\n  const [speechRecognition, setSpeechRecognition] = useState<SpeechRecognition | null>(null);\n  const [animationLevel, setAnimationLevel] = useState(0);\n  const [voiceAmplitude, setVoiceAmplitude] = useState<number[]>([0, 0, 0, 0, 0]);\n  const [errorMessage, setErrorMessage] = useState<string | null>(null);\n  const [recognitionState, setRecognitionState] = useState<'idle' | 'listening' | 'processing' | 'error'>('idle');\n  const [interimTranscript, setInterimTranscript] = useState<string>('');\n  const [isSpeaking, setIsSpeaking] = useState<boolean>(false);\n  const audioContextRef = useRef<AudioContext | null>(null);\n  const analyserRef = useRef<AnalyserNode | null>(null);\n  const mediaStreamRef = useRef<MediaStream | null>(null);\n  const startTimeRef = useRef<number>(0);\n  const speechSynthesisRef = useRef<SpeechSynthesisUtterance | null>(null);\n  const previousStateRef = useRef<string>('idle');\n\n  // Speak the current state using speech synthesis\n  const speakState = (state: string, errorMsg?: string) => {\n    // Don't speak if already speaking\n    if (isSpeaking) {\n      if (speechSynthesisRef.current) {\n        window.speechSynthesis.cancel();\n      }\n    }\n\n    // Don't repeat the same state\n    if (state === previousStateRef.current && state !== 'error') {\n      return;\n    }\n\n    previousStateRef.current = state;\n\n    // Create message based on state\n    let message = '';\n    switch (state) {\n      case 'listening':\n        message = \"I'm listening. Please speak now.\";\n        break;\n      case 'processing':\n        message = \"Processing your speech.\";\n        break;\n      case 'error':\n        message = errorMsg || \"An error occurred with speech recognition.\";\n        break;\n      case 'idle':\n        message = \"Voice input ready.\";\n        break;\n      default:\n        return; // Don't speak for unknown states\n    }\n\n    // Use speech synthesis to speak the message\n    if ('speechSynthesis' in window) {\n      const utterance = new SpeechSynthesisUtterance(message);\n      utterance.volume = 0.8;\n      utterance.rate = 1.1;\n      utterance.pitch = 1.0;\n\n      // Set voice (try to use a female voice if available)\n      const voices = window.speechSynthesis.getVoices();\n      const femaleVoice = voices.find(voice =>\n        voice.name.includes('female') ||\n        voice.name.includes('Samantha') ||\n        voice.name.includes('Google UK English Female')\n      );\n\n      if (femaleVoice) {\n        utterance.voice = femaleVoice;\n      }\n\n      // Handle events\n      utterance.onstart = () => {\n        setIsSpeaking(true);\n      };\n\n      utterance.onend = () => {\n        setIsSpeaking(false);\n        speechSynthesisRef.current = null;\n      };\n\n      utterance.onerror = (event) => {\n        console.error('Speech synthesis error:', event);\n        setIsSpeaking(false);\n        speechSynthesisRef.current = null;\n      };\n\n      // Store reference and speak\n      speechSynthesisRef.current = utterance;\n      window.speechSynthesis.speak(utterance);\n    }\n  };\n\n  // Load voices when available\n  useEffect(() => {\n    if ('speechSynthesis' in window) {\n      // Chrome needs this to load voices\n      window.speechSynthesis.onvoiceschanged = () => {\n        window.speechSynthesis.getVoices();\n      };\n    }\n  }, []);\n\n  // Audio processing for voice visualization\n  const setupAudioProcessing = async () => {\n    try {\n      // Create audio context\n      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();\n      audioContextRef.current = audioContext;\n\n      // Get microphone stream\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      mediaStreamRef.current = stream;\n\n      // Create analyser node\n      const analyser = audioContext.createAnalyser();\n      analyser.fftSize = 32; // Small FFT size for performance\n      analyserRef.current = analyser;\n\n      // Connect microphone to analyser\n      const source = audioContext.createMediaStreamSource(stream);\n      source.connect(analyser);\n\n      // Start visualization loop\n      visualizeAudio();\n    } catch (err) {\n      console.error('Error setting up audio visualization:', err);\n      setErrorMessage('Could not access microphone for visualization');\n    }\n  };\n\n  // Clean up audio processing\n  const cleanupAudioProcessing = () => {\n    if (mediaStreamRef.current) {\n      mediaStreamRef.current.getTracks().forEach((track: MediaStreamTrack) => track.stop());\n      mediaStreamRef.current = null;\n    }\n\n    if (audioContextRef.current) {\n      audioContextRef.current.close().catch(err => {\n        console.error('Error closing audio context:', err);\n      });\n      audioContextRef.current = null;\n    }\n\n    analyserRef.current = null;\n    setVoiceAmplitude([0, 0, 0, 0, 0]);\n  };\n\n  // Visualize audio data\n  const visualizeAudio = () => {\n    if (!analyserRef.current || !isListening) return;\n\n    const bufferLength = analyserRef.current.frequencyBinCount;\n    const dataArray = new Uint8Array(bufferLength);\n\n    const updateAmplitude = () => {\n      if (!analyserRef.current || !isListening) return;\n\n      // Get frequency data\n      analyserRef.current.getByteFrequencyData(dataArray);\n\n      // Calculate average amplitude from different frequency ranges\n      const bass = dataArray.slice(0, 3).reduce((a, b) => a + b, 0) / 3;\n      const midLow = dataArray.slice(3, 6).reduce((a, b) => a + b, 0) / 3;\n      const mid = dataArray.slice(6, 9).reduce((a, b) => a + b, 0) / 3;\n      const midHigh = dataArray.slice(9, 12).reduce((a, b) => a + b, 0) / 3;\n      const high = dataArray.slice(12, 15).reduce((a, b) => a + b, 0) / 3;\n\n      // Normalize values (0-1)\n      const normalized = [\n        bass / 255,\n        midLow / 255,\n        mid / 255,\n        midHigh / 255,\n        high / 255\n      ];\n\n      setVoiceAmplitude(normalized);\n\n      // Continue animation loop\n      requestAnimationFrame(updateAmplitude);\n    };\n\n    updateAmplitude();\n  };\n\n  // Animation effect\n  useEffect(() => {\n    let animationInterval: NodeJS.Timeout | null = null;\n\n    if (isListening) {\n      // Set up audio processing for visualization\n      setupAudioProcessing();\n\n      // Fallback animation for wave effect\n      animationInterval = setInterval(() => {\n        setAnimationLevel(prev => (prev + 1) % 4); // Cycle through 0-3\n      }, 300);\n    } else {\n      // Clean up audio processing\n      cleanupAudioProcessing();\n\n      if (animationInterval) {\n        clearInterval(animationInterval);\n        setAnimationLevel(0);\n      }\n    }\n\n    return () => {\n      if (animationInterval) clearInterval(animationInterval);\n      cleanupAudioProcessing();\n    };\n  }, [isListening]);\n\n  // Initialize speech recognition\n  useEffect(() => {\n    if (typeof window !== 'undefined') {\n      // Check if browser supports speech recognition\n      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n\n      if (SpeechRecognition) {\n        const recognition = new SpeechRecognition();\n\n        // Configure recognition\n        recognition.continuous = true;\n        recognition.interimResults = true;\n        recognition.maxAlternatives = 1;\n        recognition.lang = 'en-US';\n\n        // Handle interim results (while speaking)\n        recognition.onresult = (event) => {\n          let finalTranscript = '';\n          let interimTranscript = '';\n\n          // Process results\n          for (let i = event.resultIndex; i < event.results.length; i++) {\n            const transcript = event.results[i][0].transcript;\n\n            if (event.results[i].isFinal) {\n              finalTranscript += transcript;\n              setRecognitionState('processing');\n              speakState('processing');\n            } else {\n              interimTranscript += transcript;\n            }\n          }\n\n          // Update interim transcript for display\n          if (interimTranscript) {\n            setInterimTranscript(interimTranscript);\n          }\n\n          // If we have a final result, send it\n          if (finalTranscript) {\n            // Calculate speech speed (words per minute)\n            const wordCount = finalTranscript.split(/\\s+/).length;\n            const speechDuration = (Date.now() - startTimeRef.current) / 1000 / 60; // in minutes\n            const wordsPerMinute = Math.round(wordCount / speechDuration);\n\n            // Send the result with metadata\n            onSpeechResult(finalTranscript);\n\n            // Log speech analytics\n            console.log(`Speech detected: ${finalTranscript}`);\n            console.log(`Speech duration: ${(speechDuration * 60).toFixed(2)} seconds`);\n            console.log(`Words per minute: ${wordsPerMinute}`);\n\n            // Reset state\n            setInterimTranscript('');\n            setRecognitionState('idle');\n            setIsListening(false);\n          }\n        };\n\n        recognition.onerror = (event) => {\n          console.error('Speech recognition error', event.error);\n\n          let errorMsg = 'Error with speech recognition';\n          let shouldRestart = false;\n\n          // Provide more specific error messages\n          switch (event.error) {\n            case 'no-speech':\n              errorMsg = 'No speech detected. Please try speaking again.';\n              shouldRestart = true; // Auto-restart on no-speech\n              break;\n            case 'aborted':\n              errorMsg = 'Speech recognition was aborted. Restarting...';\n              shouldRestart = true; // Auto-restart on aborted\n              break;\n            case 'audio-capture':\n              errorMsg = 'Could not capture audio. Please check your microphone.';\n              break;\n            case 'network':\n              errorMsg = 'Network error occurred. Please check your connection.';\n              break;\n            case 'not-allowed':\n              errorMsg = 'Microphone access denied. Please allow microphone access.';\n              break;\n            case 'service-not-allowed':\n              errorMsg = 'Speech recognition service not allowed.';\n              break;\n            case 'bad-grammar':\n              errorMsg = 'Grammar error in speech recognition.';\n              break;\n            case 'language-not-supported':\n              errorMsg = 'Language not supported for speech recognition.';\n              break;\n            default:\n              errorMsg = `Error: ${event.error}`;\n          }\n\n          setErrorMessage(errorMsg);\n\n          // Only change state if we're not going to restart\n          if (!shouldRestart) {\n            setRecognitionState('error');\n            speakState('error', errorMsg);\n            setIsListening(false);\n          } else {\n            // For no-speech or aborted, just show a temporary message\n            setTimeout(() => {\n              setErrorMessage(null);\n\n              // Try to restart recognition if we're still supposed to be listening\n              if (isListening) {\n                try {\n                  recognition.start();\n                  console.log('Speech recognition restarted after error');\n                } catch (e) {\n                  console.error('Failed to restart speech recognition', e);\n                  setRecognitionState('error');\n                  speakState('error', 'Failed to restart speech recognition');\n                  setIsListening(false);\n                }\n              }\n            }, 1500);\n          }\n        };\n\n        recognition.onstart = () => {\n          setRecognitionState('listening');\n          startTimeRef.current = Date.now();\n          console.log('Speech recognition started');\n          speakState('listening');\n        };\n\n        recognition.onend = () => {\n          console.log('Speech recognition ended');\n\n          // If we're still supposed to be listening, restart the recognition\n          if (isListening && recognitionState === 'listening') {\n            try {\n              // Add a small delay to prevent rapid restarts\n              setTimeout(() => {\n                if (isListening) {\n                  recognition.start();\n                  console.log('Speech recognition restarted');\n                }\n              }, 300);\n            } catch (e) {\n              console.error('Failed to restart speech recognition', e);\n              setRecognitionState('error');\n              speakState('error', 'Failed to restart speech recognition');\n              setIsListening(false);\n            }\n          } else if (recognitionState === 'listening') {\n            // Only update state if we're still in listening state\n            setRecognitionState('idle');\n            setIsListening(false);\n          }\n        };\n\n        // Handle audio start/end events\n        recognition.onaudiostart = () => {\n          console.log('Audio capturing started');\n        };\n\n        recognition.onaudioend = () => {\n          console.log('Audio capturing ended');\n        };\n\n        // Handle sound start/end events\n        recognition.onsoundstart = () => {\n          console.log('Sound detected');\n        };\n\n        recognition.onsoundend = () => {\n          console.log('Sound ended');\n        };\n\n        // Handle speech start/end events\n        recognition.onspeechstart = () => {\n          console.log('Speech started');\n        };\n\n        recognition.onspeechend = () => {\n          console.log('Speech ended');\n        };\n\n        setSpeechRecognition(recognition);\n      } else {\n        setErrorMessage('Speech recognition not supported in this browser');\n        setRecognitionState('error');\n        speakState('error', 'Speech recognition not supported in this browser');\n      }\n    }\n  }, [onSpeechResult]);\n\n  const toggleListening = () => {\n    if (disabled || !speechRecognition) return;\n\n    // Cancel any ongoing speech synthesis\n    if (speechSynthesisRef.current) {\n      window.speechSynthesis.cancel();\n      speechSynthesisRef.current = null;\n      setIsSpeaking(false);\n    }\n\n    if (isListening) {\n      // Stop listening\n      speechRecognition.stop();\n      setIsListening(false);\n      setRecognitionState('idle');\n      setInterimTranscript('');\n      speakState('idle');\n    } else {\n      // Start listening\n      setErrorMessage(null);\n      setRecognitionState('listening');\n      startTimeRef.current = Date.now();\n\n      try {\n        speechRecognition.start();\n        setIsListening(true);\n        // Note: We don't call speakState here because it will be called in the onstart event\n      } catch (error) {\n        console.error('Error starting speech recognition:', error);\n        const errorMsg = 'Failed to start speech recognition. Please try again.';\n        setErrorMessage(errorMsg);\n        setRecognitionState('error');\n        speakState('error', errorMsg);\n      }\n    }\n  };\n\n  return (\n    <div className=\"voice-input-container\">\n      <button\n        className={`voice-input-button ${recognitionState === 'listening' ? 'listening' : ''} ${recognitionState === 'processing' ? 'processing' : ''} ${recognitionState === 'error' ? 'error' : ''} ${isSpeaking ? 'speaking' : ''} ${disabled ? 'disabled' : ''}`}\n        onClick={toggleListening}\n        disabled={disabled || !speechRecognition || recognitionState === 'processing' || isSpeaking}\n        title={errorMessage || (isSpeaking ? 'System is speaking' : isListening ? 'Tap to stop' : 'Tap to speak')}\n        aria-label=\"Voice input\"\n      >\n        <svg\n          className=\"microphone-svg\"\n          width=\"24\"\n          height=\"24\"\n          viewBox=\"0 0 24 24\"\n          fill=\"none\"\n          xmlns=\"http://www.w3.org/2000/svg\"\n        >\n          {/* Microphone body */}\n          <rect\n            x=\"9\"\n            y=\"2\"\n            width=\"6\"\n            height=\"12\"\n            rx=\"3\"\n            fill={isListening ? \"#FFFFFF\" : recognitionState === 'error' ? \"#FF5555\" : \"#555555\"}\n          />\n          {/* Microphone base */}\n          <path\n            d=\"M5 10V11C5 14.866 8.13401 18 12 18V18C15.866 18 19 14.866 19 11V10\"\n            stroke={isListening ? \"#FFFFFF\" : recognitionState === 'error' ? \"#FF5555\" : \"#555555\"}\n            strokeWidth=\"2\"\n            strokeLinecap=\"round\"\n          />\n          {/* Microphone stand */}\n          <line\n            x1=\"12\"\n            y1=\"18\"\n            x2=\"12\"\n            y2=\"22\"\n            stroke={isListening ? \"#FFFFFF\" : recognitionState === 'error' ? \"#FF5555\" : \"#555555\"}\n            strokeWidth=\"2\"\n            strokeLinecap=\"round\"\n          />\n          {/* Microphone base */}\n          <line\n            x1=\"8\"\n            y1=\"22\"\n            x2=\"16\"\n            y2=\"22\"\n            stroke={isListening ? \"#FFFFFF\" : recognitionState === 'error' ? \"#FF5555\" : \"#555555\"}\n            strokeWidth=\"2\"\n            strokeLinecap=\"round\"\n          />\n        </svg>\n\n        {/* Status indicator */}\n        <div className={`status-indicator ${isSpeaking ? 'speaking' : recognitionState}`}></div>\n\n        {isListening && (\n          <>\n            {/* Voice amplitude visualization */}\n            <div className=\"voice-amplitude\">\n              {voiceAmplitude.map((level, index) => (\n                <div\n                  key={index}\n                  className=\"amplitude-bar\"\n                  style={{\n                    height: `${Math.max(3, level * 30)}px`,\n                    opacity: Math.max(0.4, level),\n                    backgroundColor: `hsl(${210 + index * 15}, 80%, ${50 + level * 25}%)`,\n                    transform: `scaleY(${1 + level * 0.2})`\n                  }}\n                ></div>\n              ))}\n            </div>\n\n            {/* Fallback sound waves animation */}\n            <div className=\"sound-waves\">\n              <div className={`wave wave-1 ${animationLevel >= 1 ? 'active' : ''}`}></div>\n              <div className={`wave wave-2 ${animationLevel >= 2 ? 'active' : ''}`}></div>\n              <div className={`wave wave-3 ${animationLevel >= 3 ? 'active' : ''}`}></div>\n            </div>\n          </>\n        )}\n      </button>\n\n      {/* Speech recognition feedback */}\n      {recognitionState === 'listening' && interimTranscript && (\n        <div className=\"interim-transcript\">\n          <div className=\"transcript-text\">{interimTranscript}</div>\n          <div className=\"listening-indicator\">Listening...</div>\n        </div>\n      )}\n\n      {recognitionState === 'processing' && (\n        <div className=\"processing-indicator\">Processing...</div>\n      )}\n\n      {errorMessage && <div className=\"voice-input-error\">{errorMessage}</div>}\n    </div>\n  );\n};\n\nexport default VoiceInput;\n"],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,EAAEC,MAAM,QAAQ,OAAO;AAC1D,OAAO,kBAAkB;AAAC,SAAAC,MAAA,IAAAC,OAAA,EAAAC,QAAA,IAAAC,SAAA;AAO1B,MAAMC,UAAqC,GAAGA,CAAC;EAAEC,cAAc;EAAEC,QAAQ,GAAG;AAAM,CAAC,KAAK;EAAAC,EAAA;EACtF,MAAM,CAACC,WAAW,EAAEC,cAAc,CAAC,GAAGZ,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACa,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGd,QAAQ,CAA2B,IAAI,CAAC;EAC1F,MAAM,CAACe,cAAc,EAAEC,iBAAiB,CAAC,GAAGhB,QAAQ,CAAC,CAAC,CAAC;EACvD,MAAM,CAACiB,cAAc,EAAEC,iBAAiB,CAAC,GAAGlB,QAAQ,CAAW,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;EAC/E,MAAM,CAACmB,YAAY,EAAEC,eAAe,CAAC,GAAGpB,QAAQ,CAAgB,IAAI,CAAC;EACrE,MAAM,CAACqB,gBAAgB,EAAEC,mBAAmB,CAAC,GAAGtB,QAAQ,CAAgD,MAAM,CAAC;EAC/G,MAAM,CAACuB,iBAAiB,EAAEC,oBAAoB,CAAC,GAAGxB,QAAQ,CAAS,EAAE,CAAC;EACtE,MAAM,CAACyB,UAAU,EAAEC,aAAa,CAAC,GAAG1B,QAAQ,CAAU,KAAK,CAAC;EAC5D,MAAM2B,eAAe,GAAGzB,MAAM,CAAsB,IAAI,CAAC;EACzD,MAAM0B,WAAW,GAAG1B,MAAM,CAAsB,IAAI,CAAC;EACrD,MAAM2B,cAAc,GAAG3B,MAAM,CAAqB,IAAI,CAAC;EACvD,MAAM4B,YAAY,GAAG5B,MAAM,CAAS,CAAC,CAAC;EACtC,MAAM6B,kBAAkB,GAAG7B,MAAM,CAAkC,IAAI,CAAC;EACxE,MAAM8B,gBAAgB,GAAG9B,MAAM,CAAS,MAAM,CAAC;;EAE/C;EACA,MAAM+B,UAAU,GAAGA,CAACC,KAAa,EAAEC,QAAiB,KAAK;IACvD;IACA,IAAIV,UAAU,EAAE;MACd,IAAIM,kBAAkB,CAACK,OAAO,EAAE;QAC9BC,MAAM,CAACC,eAAe,CAACC,MAAM,CAAC,CAAC;MACjC;IACF;;IAEA;IACA,IAAIL,KAAK,KAAKF,gBAAgB,CAACI,OAAO,IAAIF,KAAK,KAAK,OAAO,EAAE;MAC3D;IACF;IAEAF,gBAAgB,CAACI,OAAO,GAAGF,KAAK;;IAEhC;IACA,IAAIM,OAAO,GAAG,EAAE;IAChB,QAAQN,KAAK;MACX,KAAK,WAAW;QACdM,OAAO,GAAG,kCAAkC;QAC5C;MACF,KAAK,YAAY;QACfA,OAAO,GAAG,yBAAyB;QACnC;MACF,KAAK,OAAO;QACVA,OAAO,GAAGL,QAAQ,IAAI,4CAA4C;QAClE;MACF,KAAK,MAAM;QACTK,OAAO,GAAG,oBAAoB;QAC9B;MACF;QACE;MAAQ;IACZ;;IAEA;IACA,IAAI,iBAAiB,IAAIH,MAAM,EAAE;MAC/B,MAAMI,SAAS,GAAG,IAAIC,wBAAwB,CAACF,OAAO,CAAC;MACvDC,SAAS,CAACE,MAAM,GAAG,GAAG;MACtBF,SAAS,CAACG,IAAI,GAAG,GAAG;MACpBH,SAAS,CAACI,KAAK,GAAG,GAAG;;MAErB;MACA,MAAMC,MAAM,GAAGT,MAAM,CAACC,eAAe,CAACS,SAAS,CAAC,CAAC;MACjD,MAAMC,WAAW,GAAGF,MAAM,CAACG,IAAI,CAACC,KAAK,IACnCA,KAAK,CAACC,IAAI,CAACC,QAAQ,CAAC,QAAQ,CAAC,IAC7BF,KAAK,CAACC,IAAI,CAACC,QAAQ,CAAC,UAAU,CAAC,IAC/BF,KAAK,CAACC,IAAI,CAACC,QAAQ,CAAC,0BAA0B,CAChD,CAAC;MAED,IAAIJ,WAAW,EAAE;QACfP,SAAS,CAACS,KAAK,GAAGF,WAAW;MAC/B;;MAEA;MACAP,SAAS,CAACY,OAAO,GAAG,MAAM;QACxB3B,aAAa,CAAC,IAAI,CAAC;MACrB,CAAC;MAEDe,SAAS,CAACa,KAAK,GAAG,MAAM;QACtB5B,aAAa,CAAC,KAAK,CAAC;QACpBK,kBAAkB,CAACK,OAAO,GAAG,IAAI;MACnC,CAAC;MAEDK,SAAS,CAACc,OAAO,GAAIC,KAAK,IAAK;QAC7BC,OAAO,CAACC,KAAK,CAAC,yBAAyB,EAAEF,KAAK,CAAC;QAC/C9B,aAAa,CAAC,KAAK,CAAC;QACpBK,kBAAkB,CAACK,OAAO,GAAG,IAAI;MACnC,CAAC;;MAED;MACAL,kBAAkB,CAACK,OAAO,GAAGK,SAAS;MACtCJ,MAAM,CAACC,eAAe,CAACqB,KAAK,CAAClB,SAAS,CAAC;IACzC;EACF,CAAC;;EAED;EACAxC,SAAS,CAAC,MAAM;IACd,IAAI,iBAAiB,IAAIoC,MAAM,EAAE;MAC/B;MACAA,MAAM,CAACC,eAAe,CAACsB,eAAe,GAAG,MAAM;QAC7CvB,MAAM,CAACC,eAAe,CAACS,SAAS,CAAC,CAAC;MACpC,CAAC;IACH;EACF,CAAC,EAAE,EAAE,CAAC;;EAEN;EACA,MAAMc,oBAAoB,GAAG,MAAAA,CAAA,KAAY;IACvC,IAAI;MACF;MACA,MAAMC,YAAY,GAAG,KAAKzB,MAAM,CAAC0B,YAAY,IAAK1B,MAAM,CAAS2B,kBAAkB,EAAE,CAAC;MACtFrC,eAAe,CAACS,OAAO,GAAG0B,YAAY;;MAEtC;MACA,MAAMG,MAAM,GAAG,MAAMC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAAEC,KAAK,EAAE;MAAK,CAAC,CAAC;MACzExC,cAAc,CAACO,OAAO,GAAG6B,MAAM;;MAE/B;MACA,MAAMK,QAAQ,GAAGR,YAAY,CAACS,cAAc,CAAC,CAAC;MAC9CD,QAAQ,CAACE,OAAO,GAAG,EAAE,CAAC,CAAC;MACvB5C,WAAW,CAACQ,OAAO,GAAGkC,QAAQ;;MAE9B;MACA,MAAMG,MAAM,GAAGX,YAAY,CAACY,uBAAuB,CAACT,MAAM,CAAC;MAC3DQ,MAAM,CAACE,OAAO,CAACL,QAAQ,CAAC;;MAExB;MACAM,cAAc,CAAC,CAAC;IAClB,CAAC,CAAC,OAAOC,GAAG,EAAE;MACZpB,OAAO,CAACC,KAAK,CAAC,uCAAuC,EAAEmB,GAAG,CAAC;MAC3DzD,eAAe,CAAC,+CAA+C,CAAC;IAClE;EACF,CAAC;;EAED;EACA,MAAM0D,sBAAsB,GAAGA,CAAA,KAAM;IACnC,IAAIjD,cAAc,CAACO,OAAO,EAAE;MAC1BP,cAAc,CAACO,OAAO,CAAC2C,SAAS,CAAC,CAAC,CAACC,OAAO,CAAEC,KAAuB,IAAKA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;MACrFrD,cAAc,CAACO,OAAO,GAAG,IAAI;IAC/B;IAEA,IAAIT,eAAe,CAACS,OAAO,EAAE;MAC3BT,eAAe,CAACS,OAAO,CAAC+C,KAAK,CAAC,CAAC,CAACC,KAAK,CAACP,GAAG,IAAI;QAC3CpB,OAAO,CAACC,KAAK,CAAC,8BAA8B,EAAEmB,GAAG,CAAC;MACpD,CAAC,CAAC;MACFlD,eAAe,CAACS,OAAO,GAAG,IAAI;IAChC;IAEAR,WAAW,CAACQ,OAAO,GAAG,IAAI;IAC1BlB,iBAAiB,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;EACpC,CAAC;;EAED;EACA,MAAM0D,cAAc,GAAGA,CAAA,KAAM;IAC3B,IAAI,CAAChD,WAAW,CAACQ,OAAO,IAAI,CAACzB,WAAW,EAAE;IAE1C,MAAM0E,YAAY,GAAGzD,WAAW,CAACQ,OAAO,CAACkD,iBAAiB;IAC1D,MAAMC,SAAS,GAAG,IAAIC,UAAU,CAACH,YAAY,CAAC;IAE9C,MAAMI,eAAe,GAAGA,CAAA,KAAM;MAC5B,IAAI,CAAC7D,WAAW,CAACQ,OAAO,IAAI,CAACzB,WAAW,EAAE;;MAE1C;MACAiB,WAAW,CAACQ,OAAO,CAACsD,oBAAoB,CAACH,SAAS,CAAC;;MAEnD;MACA,MAAMI,IAAI,GAAGJ,SAAS,CAACK,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAACC,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC;MACjE,MAAMC,MAAM,GAAGT,SAAS,CAACK,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAACC,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC;MACnE,MAAME,GAAG,GAAGV,SAAS,CAACK,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAACC,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC;MAChE,MAAMG,OAAO,GAAGX,SAAS,CAACK,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,CAACC,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC;MACrE,MAAMI,IAAI,GAAGZ,SAAS,CAACK,KAAK,CAAC,EAAE,EAAE,EAAE,CAAC,CAACC,MAAM,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,GAAGC,CAAC,EAAE,CAAC,CAAC,GAAG,CAAC;;MAEnE;MACA,MAAMK,UAAU,GAAG,CACjBT,IAAI,GAAG,GAAG,EACVK,MAAM,GAAG,GAAG,EACZC,GAAG,GAAG,GAAG,EACTC,OAAO,GAAG,GAAG,EACbC,IAAI,GAAG,GAAG,CACX;MAEDjF,iBAAiB,CAACkF,UAAU,CAAC;;MAE7B;MACAC,qBAAqB,CAACZ,eAAe,CAAC;IACxC,CAAC;IAEDA,eAAe,CAAC,CAAC;EACnB,CAAC;;EAED;EACAxF,SAAS,CAAC,MAAM;IACd,IAAIqG,iBAAwC,GAAG,IAAI;IAEnD,IAAI3F,WAAW,EAAE;MACf;MACAkD,oBAAoB,CAAC,CAAC;;MAEtB;MACAyC,iBAAiB,GAAGC,WAAW,CAAC,MAAM;QACpCvF,iBAAiB,CAACwF,IAAI,IAAI,CAACA,IAAI,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;MAC7C,CAAC,EAAE,GAAG,CAAC;IACT,CAAC,MAAM;MACL;MACA1B,sBAAsB,CAAC,CAAC;MAExB,IAAIwB,iBAAiB,EAAE;QACrBG,aAAa,CAACH,iBAAiB,CAAC;QAChCtF,iBAAiB,CAAC,CAAC,CAAC;MACtB;IACF;IAEA,OAAO,MAAM;MACX,IAAIsF,iBAAiB,EAAEG,aAAa,CAACH,iBAAiB,CAAC;MACvDxB,sBAAsB,CAAC,CAAC;IAC1B,CAAC;EACH,CAAC,EAAE,CAACnE,WAAW,CAAC,CAAC;;EAEjB;EACAV,SAAS,CAAC,MAAM;IACd,IAAI,OAAOoC,MAAM,KAAK,WAAW,EAAE;MACjC;MACA,MAAMqE,iBAAiB,GAAGrE,MAAM,CAACqE,iBAAiB,IAAIrE,MAAM,CAACsE,uBAAuB;MAEpF,IAAID,iBAAiB,EAAE;QACrB,MAAME,WAAW,GAAG,IAAIF,iBAAiB,CAAC,CAAC;;QAE3C;QACAE,WAAW,CAACC,UAAU,GAAG,IAAI;QAC7BD,WAAW,CAACE,cAAc,GAAG,IAAI;QACjCF,WAAW,CAACG,eAAe,GAAG,CAAC;QAC/BH,WAAW,CAACI,IAAI,GAAG,OAAO;;QAE1B;QACAJ,WAAW,CAACK,QAAQ,GAAIzD,KAAK,IAAK;UAChC,IAAI0D,eAAe,GAAG,EAAE;UACxB,IAAI3F,iBAAiB,GAAG,EAAE;;UAE1B;UACA,KAAK,IAAI4F,CAAC,GAAG3D,KAAK,CAAC4D,WAAW,EAAED,CAAC,GAAG3D,KAAK,CAAC6D,OAAO,CAACC,MAAM,EAAEH,CAAC,EAAE,EAAE;YAC7D,MAAMI,UAAU,GAAG/D,KAAK,CAAC6D,OAAO,CAACF,CAAC,CAAC,CAAC,CAAC,CAAC,CAACI,UAAU;YAEjD,IAAI/D,KAAK,CAAC6D,OAAO,CAACF,CAAC,CAAC,CAACK,OAAO,EAAE;cAC5BN,eAAe,IAAIK,UAAU;cAC7BjG,mBAAmB,CAAC,YAAY,CAAC;cACjCW,UAAU,CAAC,YAAY,CAAC;YAC1B,CAAC,MAAM;cACLV,iBAAiB,IAAIgG,UAAU;YACjC;UACF;;UAEA;UACA,IAAIhG,iBAAiB,EAAE;YACrBC,oBAAoB,CAACD,iBAAiB,CAAC;UACzC;;UAEA;UACA,IAAI2F,eAAe,EAAE;YACnB;YACA,MAAMO,SAAS,GAAGP,eAAe,CAACQ,KAAK,CAAC,KAAK,CAAC,CAACJ,MAAM;YACrD,MAAMK,cAAc,GAAG,CAACC,IAAI,CAACC,GAAG,CAAC,CAAC,GAAG/F,YAAY,CAACM,OAAO,IAAI,IAAI,GAAG,EAAE,CAAC,CAAC;YACxE,MAAM0F,cAAc,GAAGC,IAAI,CAACC,KAAK,CAACP,SAAS,GAAGE,cAAc,CAAC;;YAE7D;YACAnH,cAAc,CAAC0G,eAAe,CAAC;;YAE/B;YACAzD,OAAO,CAACwE,GAAG,CAAC,oBAAoBf,eAAe,EAAE,CAAC;YAClDzD,OAAO,CAACwE,GAAG,CAAC,oBAAoB,CAACN,cAAc,GAAG,EAAE,EAAEO,OAAO,CAAC,CAAC,CAAC,UAAU,CAAC;YAC3EzE,OAAO,CAACwE,GAAG,CAAC,qBAAqBH,cAAc,EAAE,CAAC;;YAElD;YACAtG,oBAAoB,CAAC,EAAE,CAAC;YACxBF,mBAAmB,CAAC,MAAM,CAAC;YAC3BV,cAAc,CAAC,KAAK,CAAC;UACvB;QACF,CAAC;QAEDgG,WAAW,CAACrD,OAAO,GAAIC,KAAK,IAAK;UAC/BC,OAAO,CAACC,KAAK,CAAC,0BAA0B,EAAEF,KAAK,CAACE,KAAK,CAAC;UAEtD,IAAIvB,QAAQ,GAAG,+BAA+B;UAC9C,IAAIgG,aAAa,GAAG,KAAK;;UAEzB;UACA,QAAQ3E,KAAK,CAACE,KAAK;YACjB,KAAK,WAAW;cACdvB,QAAQ,GAAG,gDAAgD;cAC3DgG,aAAa,GAAG,IAAI,CAAC,CAAC;cACtB;YACF,KAAK,SAAS;cACZhG,QAAQ,GAAG,+CAA+C;cAC1DgG,aAAa,GAAG,IAAI,CAAC,CAAC;cACtB;YACF,KAAK,eAAe;cAClBhG,QAAQ,GAAG,wDAAwD;cACnE;YACF,KAAK,SAAS;cACZA,QAAQ,GAAG,uDAAuD;cAClE;YACF,KAAK,aAAa;cAChBA,QAAQ,GAAG,2DAA2D;cACtE;YACF,KAAK,qBAAqB;cACxBA,QAAQ,GAAG,yCAAyC;cACpD;YACF,KAAK,aAAa;cAChBA,QAAQ,GAAG,sCAAsC;cACjD;YACF,KAAK,wBAAwB;cAC3BA,QAAQ,GAAG,gDAAgD;cAC3D;YACF;cACEA,QAAQ,GAAG,UAAUqB,KAAK,CAACE,KAAK,EAAE;UACtC;UAEAtC,eAAe,CAACe,QAAQ,CAAC;;UAEzB;UACA,IAAI,CAACgG,aAAa,EAAE;YAClB7G,mBAAmB,CAAC,OAAO,CAAC;YAC5BW,UAAU,CAAC,OAAO,EAAEE,QAAQ,CAAC;YAC7BvB,cAAc,CAAC,KAAK,CAAC;UACvB,CAAC,MAAM;YACL;YACAwH,UAAU,CAAC,MAAM;cACfhH,eAAe,CAAC,IAAI,CAAC;;cAErB;cACA,IAAIT,WAAW,EAAE;gBACf,IAAI;kBACFiG,WAAW,CAACyB,KAAK,CAAC,CAAC;kBACnB5E,OAAO,CAACwE,GAAG,CAAC,0CAA0C,CAAC;gBACzD,CAAC,CAAC,OAAOK,CAAC,EAAE;kBACV7E,OAAO,CAACC,KAAK,CAAC,sCAAsC,EAAE4E,CAAC,CAAC;kBACxDhH,mBAAmB,CAAC,OAAO,CAAC;kBAC5BW,UAAU,CAAC,OAAO,EAAE,sCAAsC,CAAC;kBAC3DrB,cAAc,CAAC,KAAK,CAAC;gBACvB;cACF;YACF,CAAC,EAAE,IAAI,CAAC;UACV;QACF,CAAC;QAEDgG,WAAW,CAACvD,OAAO,GAAG,MAAM;UAC1B/B,mBAAmB,CAAC,WAAW,CAAC;UAChCQ,YAAY,CAACM,OAAO,GAAGwF,IAAI,CAACC,GAAG,CAAC,CAAC;UACjCpE,OAAO,CAACwE,GAAG,CAAC,4BAA4B,CAAC;UACzChG,UAAU,CAAC,WAAW,CAAC;QACzB,CAAC;QAED2E,WAAW,CAACtD,KAAK,GAAG,MAAM;UACxBG,OAAO,CAACwE,GAAG,CAAC,0BAA0B,CAAC;;UAEvC;UACA,IAAItH,WAAW,IAAIU,gBAAgB,KAAK,WAAW,EAAE;YACnD,IAAI;cACF;cACA+G,UAAU,CAAC,MAAM;gBACf,IAAIzH,WAAW,EAAE;kBACfiG,WAAW,CAACyB,KAAK,CAAC,CAAC;kBACnB5E,OAAO,CAACwE,GAAG,CAAC,8BAA8B,CAAC;gBAC7C;cACF,CAAC,EAAE,GAAG,CAAC;YACT,CAAC,CAAC,OAAOK,CAAC,EAAE;cACV7E,OAAO,CAACC,KAAK,CAAC,sCAAsC,EAAE4E,CAAC,CAAC;cACxDhH,mBAAmB,CAAC,OAAO,CAAC;cAC5BW,UAAU,CAAC,OAAO,EAAE,sCAAsC,CAAC;cAC3DrB,cAAc,CAAC,KAAK,CAAC;YACvB;UACF,CAAC,MAAM,IAAIS,gBAAgB,KAAK,WAAW,EAAE;YAC3C;YACAC,mBAAmB,CAAC,MAAM,CAAC;YAC3BV,cAAc,CAAC,KAAK,CAAC;UACvB;QACF,CAAC;;QAED;QACAgG,WAAW,CAAC2B,YAAY,GAAG,MAAM;UAC/B9E,OAAO,CAACwE,GAAG,CAAC,yBAAyB,CAAC;QACxC,CAAC;QAEDrB,WAAW,CAAC4B,UAAU,GAAG,MAAM;UAC7B/E,OAAO,CAACwE,GAAG,CAAC,uBAAuB,CAAC;QACtC,CAAC;;QAED;QACArB,WAAW,CAAC6B,YAAY,GAAG,MAAM;UAC/BhF,OAAO,CAACwE,GAAG,CAAC,gBAAgB,CAAC;QAC/B,CAAC;QAEDrB,WAAW,CAAC8B,UAAU,GAAG,MAAM;UAC7BjF,OAAO,CAACwE,GAAG,CAAC,aAAa,CAAC;QAC5B,CAAC;;QAED;QACArB,WAAW,CAAC+B,aAAa,GAAG,MAAM;UAChClF,OAAO,CAACwE,GAAG,CAAC,gBAAgB,CAAC;QAC/B,CAAC;QAEDrB,WAAW,CAACgC,WAAW,GAAG,MAAM;UAC9BnF,OAAO,CAACwE,GAAG,CAAC,cAAc,CAAC;QAC7B,CAAC;QAEDnH,oBAAoB,CAAC8F,WAAW,CAAC;MACnC,CAAC,MAAM;QACLxF,eAAe,CAAC,kDAAkD,CAAC;QACnEE,mBAAmB,CAAC,OAAO,CAAC;QAC5BW,UAAU,CAAC,OAAO,EAAE,kDAAkD,CAAC;MACzE;IACF;EACF,CAAC,EAAE,CAACzB,cAAc,CAAC,CAAC;EAEpB,MAAMqI,eAAe,GAAGA,CAAA,KAAM;IAC5B,IAAIpI,QAAQ,IAAI,CAACI,iBAAiB,EAAE;;IAEpC;IACA,IAAIkB,kBAAkB,CAACK,OAAO,EAAE;MAC9BC,MAAM,CAACC,eAAe,CAACC,MAAM,CAAC,CAAC;MAC/BR,kBAAkB,CAACK,OAAO,GAAG,IAAI;MACjCV,aAAa,CAAC,KAAK,CAAC;IACtB;IAEA,IAAIf,WAAW,EAAE;MACf;MACAE,iBAAiB,CAACqE,IAAI,CAAC,CAAC;MACxBtE,cAAc,CAAC,KAAK,CAAC;MACrBU,mBAAmB,CAAC,MAAM,CAAC;MAC3BE,oBAAoB,CAAC,EAAE,CAAC;MACxBS,UAAU,CAAC,MAAM,CAAC;IACpB,CAAC,MAAM;MACL;MACAb,eAAe,CAAC,IAAI,CAAC;MACrBE,mBAAmB,CAAC,WAAW,CAAC;MAChCQ,YAAY,CAACM,OAAO,GAAGwF,IAAI,CAACC,GAAG,CAAC,CAAC;MAEjC,IAAI;QACFhH,iBAAiB,CAACwH,KAAK,CAAC,CAAC;QACzBzH,cAAc,CAAC,IAAI,CAAC;QACpB;MACF,CAAC,CAAC,OAAO8C,KAAK,EAAE;QACdD,OAAO,CAACC,KAAK,CAAC,oCAAoC,EAAEA,KAAK,CAAC;QAC1D,MAAMvB,QAAQ,GAAG,uDAAuD;QACxEf,eAAe,CAACe,QAAQ,CAAC;QACzBb,mBAAmB,CAAC,OAAO,CAAC;QAC5BW,UAAU,CAAC,OAAO,EAAEE,QAAQ,CAAC;MAC/B;IACF;EACF,CAAC;EAED,oBACE/B,OAAA;IAAK0I,SAAS,EAAC,uBAAuB;IAAAC,QAAA,gBACpC3I,OAAA;MACE0I,SAAS,EAAE,sBAAsBzH,gBAAgB,KAAK,WAAW,GAAG,WAAW,GAAG,EAAE,IAAIA,gBAAgB,KAAK,YAAY,GAAG,YAAY,GAAG,EAAE,IAAIA,gBAAgB,KAAK,OAAO,GAAG,OAAO,GAAG,EAAE,IAAII,UAAU,GAAG,UAAU,GAAG,EAAE,IAAIhB,QAAQ,GAAG,UAAU,GAAG,EAAE,EAAG;MAC7PuI,OAAO,EAAEH,eAAgB;MACzBpI,QAAQ,EAAEA,QAAQ,IAAI,CAACI,iBAAiB,IAAIQ,gBAAgB,KAAK,YAAY,IAAII,UAAW;MAC5FwH,KAAK,EAAE9H,YAAY,KAAKM,UAAU,GAAG,oBAAoB,GAAGd,WAAW,GAAG,aAAa,GAAG,cAAc,CAAE;MAC1G,cAAW,aAAa;MAAAoI,QAAA,gBAExB3I,OAAA;QACE0I,SAAS,EAAC,gBAAgB;QAC1BI,KAAK,EAAC,IAAI;QACVC,MAAM,EAAC,IAAI;QACXC,OAAO,EAAC,WAAW;QACnBC,IAAI,EAAC,MAAM;QACXC,KAAK,EAAC,4BAA4B;QAAAP,QAAA,gBAGlC3I,OAAA;UACEmJ,CAAC,EAAC,GAAG;UACLC,CAAC,EAAC,GAAG;UACLN,KAAK,EAAC,GAAG;UACTC,MAAM,EAAC,IAAI;UACXM,EAAE,EAAC,GAAG;UACNJ,IAAI,EAAE1I,WAAW,GAAG,SAAS,GAAGU,gBAAgB,KAAK,OAAO,GAAG,SAAS,GAAG;QAAU;UAAAqI,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACtF,CAAC,eAEFzJ,OAAA;UACE0J,CAAC,EAAC,oEAAoE;UACtEC,MAAM,EAAEpJ,WAAW,GAAG,SAAS,GAAGU,gBAAgB,KAAK,OAAO,GAAG,SAAS,GAAG,SAAU;UACvF2I,WAAW,EAAC,GAAG;UACfC,aAAa,EAAC;QAAO;UAAAP,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACtB,CAAC,eAEFzJ,OAAA;UACE8J,EAAE,EAAC,IAAI;UACPC,EAAE,EAAC,IAAI;UACPC,EAAE,EAAC,IAAI;UACPC,EAAE,EAAC,IAAI;UACPN,MAAM,EAAEpJ,WAAW,GAAG,SAAS,GAAGU,gBAAgB,KAAK,OAAO,GAAG,SAAS,GAAG,SAAU;UACvF2I,WAAW,EAAC,GAAG;UACfC,aAAa,EAAC;QAAO;UAAAP,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACtB,CAAC,eAEFzJ,OAAA;UACE8J,EAAE,EAAC,GAAG;UACNC,EAAE,EAAC,IAAI;UACPC,EAAE,EAAC,IAAI;UACPC,EAAE,EAAC,IAAI;UACPN,MAAM,EAAEpJ,WAAW,GAAG,SAAS,GAAGU,gBAAgB,KAAK,OAAO,GAAG,SAAS,GAAG,SAAU;UACvF2I,WAAW,EAAC,GAAG;UACfC,aAAa,EAAC;QAAO;UAAAP,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACtB,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACC,CAAC,eAGNzJ,OAAA;QAAK0I,SAAS,EAAE,oBAAoBrH,UAAU,GAAG,UAAU,GAAGJ,gBAAgB;MAAG;QAAAqI,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAM,CAAC,EAEvFlJ,WAAW,iBACVP,OAAA,CAAAE,SAAA;QAAAyI,QAAA,gBAEE3I,OAAA;UAAK0I,SAAS,EAAC,iBAAiB;UAAAC,QAAA,EAC7B9H,cAAc,CAACqJ,GAAG,CAAC,CAACC,KAAK,EAAEC,KAAK,kBAC/BpK,OAAA;YAEE0I,SAAS,EAAC,eAAe;YACzB2B,KAAK,EAAE;cACLtB,MAAM,EAAE,GAAGpB,IAAI,CAAC2C,GAAG,CAAC,CAAC,EAAEH,KAAK,GAAG,EAAE,CAAC,IAAI;cACtCI,OAAO,EAAE5C,IAAI,CAAC2C,GAAG,CAAC,GAAG,EAAEH,KAAK,CAAC;cAC7BK,eAAe,EAAE,OAAO,GAAG,GAAGJ,KAAK,GAAG,EAAE,UAAU,EAAE,GAAGD,KAAK,GAAG,EAAE,IAAI;cACrEM,SAAS,EAAE,UAAU,CAAC,GAAGN,KAAK,GAAG,GAAG;YACtC;UAAE,GAPGC,KAAK;YAAAd,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAQN,CACP;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACC,CAAC,eAGNzJ,OAAA;UAAK0I,SAAS,EAAC,aAAa;UAAAC,QAAA,gBAC1B3I,OAAA;YAAK0I,SAAS,EAAE,eAAe/H,cAAc,IAAI,CAAC,GAAG,QAAQ,GAAG,EAAE;UAAG;YAAA2I,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAM,CAAC,eAC5EzJ,OAAA;YAAK0I,SAAS,EAAE,eAAe/H,cAAc,IAAI,CAAC,GAAG,QAAQ,GAAG,EAAE;UAAG;YAAA2I,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAM,CAAC,eAC5EzJ,OAAA;YAAK0I,SAAS,EAAE,eAAe/H,cAAc,IAAI,CAAC,GAAG,QAAQ,GAAG,EAAE;UAAG;YAAA2I,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAM,CAAC;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACzE,CAAC;MAAA,eACN,CACH;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACK,CAAC,EAGRxI,gBAAgB,KAAK,WAAW,IAAIE,iBAAiB,iBACpDnB,OAAA;MAAK0I,SAAS,EAAC,oBAAoB;MAAAC,QAAA,gBACjC3I,OAAA;QAAK0I,SAAS,EAAC,iBAAiB;QAAAC,QAAA,EAAExH;MAAiB;QAAAmI,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAM,CAAC,eAC1DzJ,OAAA;QAAK0I,SAAS,EAAC,qBAAqB;QAAAC,QAAA,EAAC;MAAY;QAAAW,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAK,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACpD,CACN,EAEAxI,gBAAgB,KAAK,YAAY,iBAChCjB,OAAA;MAAK0I,SAAS,EAAC,sBAAsB;MAAAC,QAAA,EAAC;IAAa;MAAAW,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CACzD,EAEA1I,YAAY,iBAAIf,OAAA;MAAK0I,SAAS,EAAC,mBAAmB;MAAAC,QAAA,EAAE5H;IAAY;MAAAuI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACrE,CAAC;AAEV,CAAC;AAACnJ,EAAA,CAniBIH,UAAqC;AAAAuK,EAAA,GAArCvK,UAAqC;AAqiB3C,eAAeA,UAAU;AAAC,IAAAuK,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}